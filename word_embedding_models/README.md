# Find and join n-grams as tokens
Read text files and identify frequent bigrams, replace with joined tokens (e.g., New York -> New_York) and save into single file 
<code>find_phrases.py <input file 1> [<input file 2> ...] <output file></code>
Repeat to identify frequent trigrams etc. (New_York Times -> New_York_Times)

